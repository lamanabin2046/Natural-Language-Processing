{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8541b76d-3f8d-4f35-889b-3c66b481e42c",
   "metadata": {},
   "source": [
    "### Skip gram without negative sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2869eb91-b7e5-4feb-b0f2-8ed769e0d8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import nltk\n",
    "nltk.download('reuters')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932ab647-c940-498f-a3a2-bc03133112f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the version\n",
    "np.__version__, torch.__version__, matplotlib.__version__, nltk.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ccc98ec-61cd-409b-9669-413cb965c47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936bbe0b-2261-4c5e-9ef2-900d5028683d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import reuters\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0358db-b5de-4cfb-9411-5eb6d07e6515",
   "metadata": {},
   "source": [
    "### Word2vec Skip with Without Negative Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd01cf71-e7c8-47c6-834f-48acf71e53f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to store all Reuters news documents\n",
    "documents = []\n",
    "\n",
    "# Loop through each file ID available in the Reuters corpus\n",
    "for fileid in reuters.fileids():\n",
    "    \n",
    "    # Read the full raw text of the current Reuters news file\n",
    "    text = reuters.raw(fileid)\n",
    "    \n",
    "    # Append (store) the text of the document into the documents list\n",
    "    documents.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9d75f5-1824-48de-b32d-9000c7eb67f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = corpus[:100]  # limit corpus size for faster training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc996f7-9337-4e36-813e-5203722c5d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get word sequences and extract unique words (vocabulary)\n",
    "\n",
    "# Define a lambda function to flatten a list of lists into a single list\n",
    "flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "\n",
    "# Flatten the corpus (list of documents) and extract unique words using set\n",
    "vocab = list(set(flatten(corpus)))\n",
    "\n",
    "# Display the first word in the vocabulary list\n",
    "vocab[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340861a4-00dd-4aa4-b21a-53166d54c72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vocab size\n",
    "voc_size = len(vocab)\n",
    "print(voc_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28620ca8-73ee-496f-8158-6caa66f4264f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numericalization: convert words into numerical indices\n",
    "\n",
    "# Create a dictionary that maps each word in the vocabulary to a unique integer index\n",
    "word2index = {w: i for i, w in enumerate(vocab)}\n",
    "word2index['lives'] # Get the index of the first word in the vocabulary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d8a602-a139-4e8e-9f60-bf33682b8069",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append a special token for unknown (out-of-vocabulary) words\n",
    "vocab.append('<UNK>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32248c25-5fec-487d-ac52-ed75888733ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vocab size\n",
    "voc_size = len(vocab)\n",
    "print(voc_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6ffcb5-4cad-4e27-a813-e5aad7a55fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign index 0 to the special <UNK> (unknown) token,\n",
    "# so that all unseen or out-of-vocabulary words map to index 0\n",
    "word2index['<UNK>'] = 0\n",
    "index2word[0] = '<UNK>'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1526a2d-1412-4b58-b8e5-784cdc24b1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a reverse mapping from index to word\n",
    "# This dictionary allows us to convert numerical indices back into words\n",
    "# It is useful for interpreting model outputs and debugging\n",
    "index2word = {v: k for k, v in word2index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9743cb9d-a29e-45ed-b4f4-8f856d24a8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_batch(batch_size, word_sequence, window_size=2):\n",
    "    \"\"\"\n",
    "    Generates a random batch of (target, context) pairs\n",
    "    for Skip-gram model WITHOUT negative sampling.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create an empty list to store all (target, context) skip-gram pairs\n",
    "    skip_grams = []\n",
    "    \n",
    "    # Loop through each sentence/document in the corpus\n",
    "    for sent in corpus:\n",
    "        \n",
    "        # Iterate over each word position in the sentence\n",
    "        for i in range(1,len(sent)-1):   # dynamic range, not fixed at edges\n",
    "            \n",
    "            # Get the index of the target (center) word\n",
    "            target = word2index[sent[i]]\n",
    "            \n",
    "            # Generate context words within the dynamic window\n",
    "            for j in range(i - window_size, i + window_size + 1):\n",
    "                \n",
    "                # Skip the target word itself and ensure valid sentence bounds\n",
    "                if j != i and 0 <= j < len(sent):\n",
    "                    \n",
    "                    # Get the index of the context word\n",
    "                    context = word2index[sent[j]]\n",
    "                    \n",
    "                    # Append (target, context) pair to skip-grams list\n",
    "                    skip_grams.append([target, context])\n",
    "    \n",
    "    # Initialize lists to store randomly selected inputs and labels\n",
    "    random_inputs = []\n",
    "    random_labels = []\n",
    "    \n",
    "    # Randomly select batch_size indices from all skip-gram pairs (without replacement)\n",
    "    random_index = np.random.choice(range(len(skip_grams)), batch_size, replace=False)\n",
    "        \n",
    "    # Collect the selected skip-gram pairs into input and label lists\n",
    "    for i in random_index:\n",
    "        random_inputs.append([skip_grams[i][0]])   # target word index\n",
    "        random_labels.append([skip_grams[i][1]])   # context word index\n",
    "            \n",
    "    # Return the batch as NumPy arrays\n",
    "    return np.array(random_inputs), np.array(random_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd4f2d9-3072-40e7-a70e-d492f67feb1c",
   "metadata": {},
   "source": [
    "### Testing the Input and Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be617f2-68ab-4843-87bc-f7508800e939",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of (target, context) pairs to include in one training batch\n",
    "batch_size = 32\n",
    "\n",
    "# Generate a random batch of Skip-Gram training data\n",
    "# input_batch  → target (center) word indices\n",
    "# target_batch → context (neighbor) word indices\n",
    "input_batch, target_batch = random_batch(batch_size, corpus, window_size=5)\n",
    "\n",
    "# Print the target word indices in the batch\n",
    "print(\"Input: \", input_batch)\n",
    "\n",
    "# Print the corresponding context word indices in the batch\n",
    "print(\"Target: \", target_batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e476ea-973f-402a-b09e-f2e46fa44f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Skipgram(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, emb_size):\n",
    "        # Initialize the parent nn.Module class\n",
    "        super(Skipgram, self).__init__()\n",
    "        \n",
    "        # Embedding matrix for center (input) words\n",
    "        # Size: [vocab_size, emb_size]\n",
    "        self.embedding_v = nn.Embedding(vocab_size, emb_size)\n",
    "        \n",
    "        # Embedding matrix for context (output) words\n",
    "        # Size: [vocab_size, emb_size]\n",
    "        self.embedding_u = nn.Embedding(vocab_size, emb_size)\n",
    "    \n",
    "    def forward(self, center_words, target_words, all_vocabs):\n",
    "        \"\"\"\n",
    "        center_words : indices of center words [batch_size, 1]\n",
    "        target_words : indices of context words [batch_size, 1]\n",
    "        all_vocabs   : indices of all words in vocabulary [batch_size, vocab_size]\n",
    "        \"\"\"\n",
    "        \n",
    "        # Look up embeddings for center words\n",
    "        # Output shape: [batch_size, 1, emb_size]\n",
    "        center_embeds = self.embedding_v(center_words)\n",
    "        \n",
    "        # Look up embeddings for target (context) words\n",
    "        # Output shape: [batch_size, 1, emb_size]\n",
    "        target_embeds = self.embedding_u(target_words)\n",
    "        \n",
    "        # Look up embeddings for all vocabulary words\n",
    "        # Output shape: [batch_size, vocab_size, emb_size]\n",
    "        all_embeds = self.embedding_u(all_vocabs)\n",
    "        \n",
    "        # Compute dot product between center and target embeddings\n",
    "        # [batch_size, 1, emb_size] × [batch_size, emb_size, 1]\n",
    "        # → [batch_size, 1, 1] → squeeze → [batch_size, 1]\n",
    "        scores = target_embeds.bmm(\n",
    "            center_embeds.transpose(1, 2)\n",
    "        ).squeeze(2)\n",
    "\n",
    "        # Compute dot product between center word and all vocabulary words\n",
    "        # [batch_size, vocab_size, emb_size] × [batch_size, emb_size, 1]\n",
    "        # → [batch_size, vocab_size, 1] → squeeze → [batch_size, vocab_size]\n",
    "        norm_scores = all_embeds.bmm(\n",
    "            center_embeds.transpose(1, 2)\n",
    "        ).squeeze(2)\n",
    "\n",
    "        # Compute Negative Log Likelihood loss using softmax\n",
    "        # log( exp(target_score) / sum(exp(all_vocab_scores)) )\n",
    "        # Final loss is a scalar\n",
    "        nll = -torch.mean(\n",
    "            torch.log(\n",
    "                torch.exp(scores) /\n",
    "                torch.sum(torch.exp(norm_scores), 1).unsqueeze(1)\n",
    "            )\n",
    "        )\n",
    "            \n",
    "        # Return the scalar loss value\n",
    "        return nll\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d188d8d-06b2-4e79-a5fa-aed9eb900b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set embedding size to 2 so that word embeddings can be visualized in 2D plots\n",
    "embedding_size = 2  \n",
    "\n",
    "# Create the Skip-Gram model\n",
    "# voc_size      → total number of unique words in the vocabulary\n",
    "# embedding_size → dimension of each word embedding\n",
    "# .to(device)   → move the model to CPU or GPU\n",
    "model_sg = Skipgram(voc_size, embedding_size).to(device)\n",
    "\n",
    "# Define the optimizer for training the model\n",
    "# Adam optimizer adapts learning rates for faster and stable convergence\n",
    "# lr = 0.001 is the learning rate\n",
    "optimizer = optim.Adam(model_sg.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a071eea-2ffb-467d-9800-1b0538fbcb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sequence(seq, word2index):\n",
    "    # Convert a sequence of words into a sequence of numerical indices\n",
    "    # If a word is not found in word2index, map it to the <UNK> token\n",
    "    idxs = list(\n",
    "        map(\n",
    "            lambda w: word2index[w] if word2index.get(w) is not None else word2index[\"<UNK>\"],\n",
    "            seq\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Convert the list of indices into a PyTorch LongTensor\n",
    "    return torch.LongTensor(idxs)\n",
    "\n",
    "\n",
    "# Prepare indices for all vocabulary words\n",
    "# This is used in the normalization (softmax) step of Skip-Gram probability calculation\n",
    "all_vocabs = prepare_sequence(list(vocab), word2index)\n",
    "\n",
    "# Expand the vocabulary indices across the batch dimension\n",
    "# Shape changes from [voc_size] → [batch_size, voc_size]\n",
    "all_vocabs = all_vocabs.expand(batch_size, len(vocab))\n",
    "\n",
    "# Move the tensor to the selected device (CPU or GPU)\n",
    "all_vocabs = all_vocabs.to(device)\n",
    "\n",
    "# Display the shape of the all_vocabs tensor\n",
    "all_vocabs.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b99ae6e-e8bc-4b02-90ae-7dc4c48f3c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    # Calculate the total time taken for an epoch (in seconds)\n",
    "    elapsed_time = end_time - start_time\n",
    "    \n",
    "    # Convert total elapsed time into minutes\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    \n",
    "    # Calculate the remaining seconds after converting to minutes\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    \n",
    "    # Return elapsed time as (minutes, seconds)\n",
    "    return elapsed_mins, elapsed_secs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd003fe-cab2-4483-ae6e-7b669bcf1378",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# -------------------- Training --------------------\n",
    "\n",
    "# Define the total number of epochs for training the model\n",
    "num_epochs = 5000\n",
    "\n",
    "# >>> ADD: record total training start time\n",
    "total_start_time = time.time()\n",
    "\n",
    "# Loop over each epoch\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    # Record the start time of the current epoch\n",
    "    start = time.time()\n",
    "    \n",
    "    # Generate a random batch of Skip-Gram (center, context) word pairs\n",
    "    input_batch, target_batch = random_batch(batch_size, corpus)\n",
    "    \n",
    "    # Convert input batch (center words) to PyTorch LongTensor and move to device\n",
    "    # Shape: [batch_size, 1]\n",
    "    input_batch  = torch.LongTensor(input_batch).to(device)\n",
    "    \n",
    "    # Convert target batch (context words) to PyTorch LongTensor and move to device\n",
    "    # Shape: [batch_size, 1]\n",
    "    target_batch = torch.LongTensor(target_batch).to(device)\n",
    "\n",
    "    # Reset gradients from the previous iteration\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Forward pass: compute the Skip-Gram loss\n",
    "    loss = model_sg(input_batch, target_batch, all_vocabs)\n",
    "    \n",
    "    # Backward pass: compute gradients using backpropagation\n",
    "    loss.backward()\n",
    "    \n",
    "    # Update model parameters using the optimizer\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Record the end time of the current epoch\n",
    "    end = time.time()\n",
    "    \n",
    "    # Calculate the time taken for the current epoch\n",
    "    epoch_mins, epoch_secs = epoch_time(start, end)\n",
    "\n",
    "    # Print training status every 1000 epochs\n",
    "    if (epoch + 1) % 1000 == 0:\n",
    "        print(f\"Epoch: {epoch + 1} | cost: {loss:.6f} | time: {epoch_mins}m {epoch_secs}s\")\n",
    "\n",
    "# >>> ADD: record total training end time\n",
    "total_end_time = time.time()\n",
    "\n",
    "# >>> ADD: compute total training time\n",
    "total_training_time = total_end_time - total_start_time\n",
    "\n",
    "# >>> ADD: final reporting (for Task-2 table)\n",
    "print(f\"\\nTotal training time (Skip-gram): {total_training_time:.2f} seconds\")\n",
    "print(f\"Final training loss (Skip-gram): {loss.item():.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b91fbc8-4dba-49ea-af5d-46871eff28f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the model\n",
    "torch.save(model_sg.state_dict(), 'model/skipgram_without_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac47414-c3b0-480e-a88b-574fd07c65cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of vocabs\n",
    "vocab[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60184ea3-c6e8-4a1d-9c53-49add022dd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "word = vocab[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb51d88-6ccf-4a13-9c9b-e9d44e5df7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#numericalization\n",
    "id = word2index[word]\n",
    "id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6df1f4-f30c-422d-9e4c-b7c8b7a63ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_tensor = torch.LongTensor([id])\n",
    "id_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ff0e3a-2cfe-4325-a72f-b4c01226d4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the embedding by averaging\n",
    "v_embed = model_sg.embedding_v(id_tensor.to(device))\n",
    "u_embed = model_sg.embedding_u(id_tensor.to(device))\n",
    "\n",
    "v_embed, u_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0fb6c1-a3c6-416c-8d28-88999c7f2a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#average to get the word embedding\n",
    "word_embed = (v_embed + u_embed) / 2\n",
    "word_embed[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa9e61b-fc70-4cfb-bdb9-93a0915fa9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embed_sg(word):\n",
    "    id_tensor = torch.LongTensor([word2index[word]]).to(device)   # ← move to GPU\n",
    "    v_embed = model_sg.embedding_v(id_tensor)\n",
    "    u_embed = model_sg.embedding_u(id_tensor)\n",
    "    word_embed = (v_embed + u_embed) / 2\n",
    "    \n",
    "    return word_embed[0][0].item(), word_embed[0][1].item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ed706f-49ed-4d5e-a991-68bd16c21e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "for i, word in enumerate(vocab[:50]): #loop each unique vocab\n",
    "    x, y = get_embed_sg(word)\n",
    "    plt.scatter(x, y)\n",
    "    plt.annotate(word, xy=(x, y), xytext=(5, 2), textcoords='offset points')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c007a13d-3f9a-4e4b-8a34-05897bc9fb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "def cos_sim(a, b):\n",
    "    return dot(a, b) / (norm(a) * norm(b))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af20fce6-88f0-4899-9e7f-8ce737d1514e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tobacco_vec   = get_embed_sg(\"tobacco\")\n",
    "fruit_vec = get_embed_sg(\"fruit\")\n",
    "\n",
    "print(\"Tobacco  vs fruit:\", cos_sim(tobacco_vec, fruit_vec))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deab8922-a8e2-4845-84ab-1b2e5e8bd151",
   "metadata": {},
   "source": [
    "### Skip gram with Negative Sampling`m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb08247-18dd-451b-a1d9-a489fc958b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cd8ee8-f94e-4f3c-b3ad-a372bd314136",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Count the frequency of each word in the entire corpus\n",
    "# flatten(corpus) converts the list of sentences into a single list of words\n",
    "word_count = Counter(flatten(corpus))\n",
    "\n",
    "# Calculate the total number of words in the corpus\n",
    "# This is the sum of frequencies of all unique words\n",
    "num_total_words = sum([c for w, c in word_count.items()])\n",
    "\n",
    "# Display the total word count\n",
    "num_total_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25cb7a75-f513-4d3c-8dfc-6eb5e0426899",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count[',']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e6ee8a-bde1-4f41-9d1f-fe1a7fa69699",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_total_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402a420a-9f77-4cd2-99cf-c05f682a5686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a unigram table for negative sampling\n",
    "# The table stores words multiple times according to their adjusted frequencies\n",
    "\n",
    "unigram_table = []\n",
    "\n",
    "# Loop through each word in the vocabulary\n",
    "for vo in vocab:\n",
    "    \n",
    "    # Calculate the adjusted unigram probability for the word\n",
    "    # word_count[vo] / num_total_words  -> original unigram probability\n",
    "    # exponent 0.75                    -> smoothing factor (as in Word2Vec)\n",
    "    # division by Z                    -> normalization constant\n",
    "    prob = (word_count[vo] / num_total_words) ** 0.75 / Z\n",
    "    \n",
    "    # Add the word to the unigram table multiple times\n",
    "    # More frequent words appear more often in the table\n",
    "    unigram_table.extend([vo] * int(prob))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2883fa23-30a3-4322-be97-9a6fb1b875a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(unigram_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3dc412-917a-4c70-a92d-c5a1afc14a81",
   "metadata": {},
   "source": [
    "### 3.Negative sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715e5ae5-20de-4027-bcdc-8529cc10db7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "\n",
    "def prepare_sequence(seq, word2index):\n",
    "    # Convert a sequence of words into their corresponding numerical indices\n",
    "    # If a word is not found in the vocabulary, map it to the <UNK> token\n",
    "    idxs = list(\n",
    "        map(\n",
    "            lambda w: word2index[w] if word2index.get(w) is not None else word2index[\"<UNK>\"],\n",
    "            seq\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Return the indices as a PyTorch LongTensor\n",
    "    return torch.LongTensor(idxs)\n",
    "\n",
    "\n",
    "def negative_sampling(targets, unigram_table, k):\n",
    "    # targets       → tensor containing target word indices [batch_size, 1]\n",
    "    # unigram_table → list of words sampled according to unigram distribution\n",
    "    # k             → number of negative samples per target word\n",
    "    \n",
    "    # Get the number of samples in the batch\n",
    "    batch_size = targets.shape[0]\n",
    "    \n",
    "    # List to store negative samples for the whole batch\n",
    "    neg_samples = []\n",
    "    \n",
    "    # Loop over each target word in the batch\n",
    "    for i in range(batch_size):\n",
    "        \n",
    "        # List to store negative samples for one target word\n",
    "        nsample = []\n",
    "        \n",
    "        # Extract the target word index as a Python integer\n",
    "        target_index = targets[i].item()\n",
    "        \n",
    "        # Sample k negative words\n",
    "        while len(nsample) < k:\n",
    "            \n",
    "            # Randomly select a word from the unigram table\n",
    "            neg = random.choice(unigram_table)\n",
    "            \n",
    "            # Skip if the sampled word is the same as the target word\n",
    "            if word2index[neg] == target_index:\n",
    "                continue\n",
    "            \n",
    "            # Add the negative word to the sample list\n",
    "            nsample.append(neg)\n",
    "\n",
    "        # Convert negative word samples to indices and reshape to [1, k]\n",
    "        neg_samples.append(\n",
    "            prepare_sequence(nsample, word2index).view(1, -1)\n",
    "        )\n",
    "    \n",
    "    # Concatenate all negative samples into a tensor of shape [batch_size, k]\n",
    "    # and move it to the appropriate device (CPU/GPU)\n",
    "    return torch.cat(neg_samples).to(device)  # [batch_size, k]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73760538-0042-4345-a14f-ff4204cd596b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_neg = 3\n",
    "negative_sampling(target_batch,unigram_table,num_neg)[:3]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3c5bf2-a618-4e6f-9ae7-06028cc21c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_batch[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6b5cdb-a1d0-4a4c-9ca7-78da5975da7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29afaaec-76e5-433c-947c-62cd50b3a383",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkipgramNegSampling(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, emb_size):\n",
    "        # Initialize the parent nn.Module class\n",
    "        super(SkipgramNegSampling, self).__init__()\n",
    "        \n",
    "        # Embedding matrix for center (input) words\n",
    "        # Shape: [vocab_size, emb_size]\n",
    "        self.embedding_v = nn.Embedding(vocab_size, emb_size)\n",
    "        \n",
    "        # Embedding matrix for context/output words\n",
    "        # Shape: [vocab_size, emb_size]\n",
    "        self.embedding_u = nn.Embedding(vocab_size, emb_size)\n",
    "        \n",
    "        # Log-sigmoid function used in negative sampling loss\n",
    "        self.logsigmoid = nn.LogSigmoid()\n",
    "                    \n",
    "    def forward(self, center_words, target_words, negative_words):\n",
    "        \"\"\"\n",
    "        center_words   : indices of center words [batch_size, 1]\n",
    "        target_words   : indices of positive context words [batch_size, 1]\n",
    "        negative_words : indices of negative samples [batch_size, k]\n",
    "        \"\"\"\n",
    "        \n",
    "        # Look up embeddings for center words\n",
    "        # Shape: [batch_size, 1, emb_size]\n",
    "        center_embeds = self.embedding_v(center_words)\n",
    "        \n",
    "        # Look up embeddings for positive (true) context words\n",
    "        # Shape: [batch_size, 1, emb_size]\n",
    "        target_embeds = self.embedding_u(target_words)\n",
    "        \n",
    "        # Look up embeddings for negative samples and negate them\n",
    "        # Shape: [batch_size, k, emb_size]\n",
    "        # Negation is used to simplify the negative sampling loss computation\n",
    "        neg_embeds = -self.embedding_u(negative_words)\n",
    "        \n",
    "        # Compute dot product between center and positive context embeddings\n",
    "        # [batch_size, 1, emb_size] × [batch_size, emb_size, 1]\n",
    "        # → [batch_size, 1, 1] → squeeze → [batch_size, 1]\n",
    "        positive_score = target_embeds.bmm(\n",
    "            center_embeds.transpose(1, 2)\n",
    "        ).squeeze(2)\n",
    "        \n",
    "        # Compute dot product between center embeddings and negative samples\n",
    "        # [batch_size, k, emb_size] × [batch_size, emb_size, 1]\n",
    "        # → [batch_size, k, 1]\n",
    "        negative_score = neg_embeds.bmm(\n",
    "            center_embeds.transpose(1, 2)\n",
    "        )\n",
    "        \n",
    "        # Compute negative sampling loss:\n",
    "        # log σ(u_o^T v_c) + Σ log σ(−u_k^T v_c)\n",
    "        loss = (\n",
    "            self.logsigmoid(positive_score)\n",
    "            + torch.sum(self.logsigmoid(negative_score), 1)\n",
    "        )\n",
    "                \n",
    "        # Return the mean negative log-likelihood loss (scalar)\n",
    "        return -torch.mean(loss)\n",
    "    \n",
    "    def prediction(self, inputs):\n",
    "        # Retrieve embeddings for given input word indices\n",
    "        # Used for inference or visualization\n",
    "        embeds = self.embedding_v(inputs)\n",
    "        \n",
    "        return embeds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f3004e-f452-44bc-9353-a7164cbeeb17",
   "metadata": {},
   "source": [
    "### 5. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc63bf2-90f8-446f-a96a-59862662bfe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size     = 2 # mini-batch size\n",
    "embedding_size = 2 #so we can later plot\n",
    "model_sg_neg   = SkipgramNegSampling(voc_size, embedding_size).to(device)\n",
    "num_neg        = 10 # num of negative sampling\n",
    "\n",
    "optimizer = optim.Adam(model_sg_neg.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c42c78-e5af-43ec-a681-6da323f8ed78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f047ef2-0736-4995-9b80-6c7953f79b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# -------------------- Training Loop (Negative Sampling) --------------------\n",
    "\n",
    "# Define the total number of training epochs\n",
    "num_epochs = 5000\n",
    "\n",
    "# >>> ADD: record total training start time (for Task-2)\n",
    "total_start_time = time.time()\n",
    "\n",
    "# Loop over each epoch\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    # Record the start time of the current epoch\n",
    "    start = time.time()\n",
    "    \n",
    "    # Generate a random batch of Skip-Gram (center, context) pairs\n",
    "    input_batch, target_batch = random_batch(batch_size, corpus)\n",
    "    \n",
    "    # Convert input batch (center words) to PyTorch LongTensor\n",
    "    # Shape: [batch_size, 1]\n",
    "    input_batch = torch.LongTensor(input_batch).to(device)\n",
    "    \n",
    "    1  # (no effect, left as-is per your request)\n",
    "    \n",
    "    # Convert target batch (positive context words) to PyTorch LongTensor\n",
    "    # Shape: [batch_size, 1]\n",
    "    target_batch = torch.LongTensor(target_batch).to(device)\n",
    "    \n",
    "    # Generate negative samples for each target word\n",
    "    # Shape: [batch_size, num_neg]\n",
    "    negs_batch = negative_sampling(target_batch, unigram_table, num_neg)\n",
    "    \n",
    "    # Clear previously accumulated gradients\n",
    "    optimizer.zero_grad()\n",
    "        \n",
    "    # Forward pass: compute loss using Skip-Gram with Negative Sampling\n",
    "    loss = model_sg_neg(input_batch, target_batch, negs_batch)\n",
    "    \n",
    "    # Record the end time of the current epoch\n",
    "    end = time.time()\n",
    "    \n",
    "    # Calculate the time taken for the current epoch\n",
    "    epoch_mins, epoch_secs = epoch_time(start, end)\n",
    "    \n",
    "    # Backward pass: compute gradients via backpropagation\n",
    "    loss.backward()\n",
    "    \n",
    "    # Update model parameters using the optimizer\n",
    "    optimizer.step()\n",
    "\n",
    "    # Print training progress every 1000 epochs\n",
    "    if (epoch + 1) % 1000 == 0:\n",
    "        print(f\"Epoch: {epoch + 1} | cost: {loss:.6f} | time: {epoch_mins}m {epoch_secs}s\")\n",
    "\n",
    "# >>> ADD: record total training end time\n",
    "total_end_time = time.time()\n",
    "\n",
    "# >>> ADD: compute total training time\n",
    "total_training_time = total_end_time - total_start_time\n",
    "\n",
    "# >>> ADD: final reporting for Task-2\n",
    "print(f\"\\nTotal training time (Skip-gram + NEG): {total_training_time:.2f} seconds\")\n",
    "print(f\"Final training loss (Skip-gram + NEG): {loss.item():.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555da875-29fd-41f3-b66a-08ce8f11929e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "torch.save(model_sg_neg.state_dict(), 'model/skipgram_neg_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8f0e76-1bc9-4003-9231-57f2fd86f4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of vocabs\n",
    "vocab[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf527fd-a856-49db-912c-32805d6ed57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "word = vocab[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b14da50-c744-49fa-bcda-b2ba5df9f6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#numericalization\n",
    "id = word2index[word]\n",
    "id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa1828a-bcf4-41fa-9fd6-6fafa246c2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_tensor = torch.LongTensor([id])\n",
    "id_tensor = id_tensor.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e6d993-5797-45c1-8de2-076912cc83f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(id_tensor.device)\n",
    "print(model_sg_neg.embedding_v.weight.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e44fe0-0fdf-474a-b891-50e4bac92bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the embedding by averaging\n",
    "v_embed = model_sg_neg.embedding_v(id_tensor)\n",
    "u_embed = model_sg_neg.embedding_u(id_tensor)\n",
    "\n",
    "v_embed, u_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5eb06e1-c780-463f-b1f3-2b362d6fc00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#average to get the word embedding\n",
    "word_embed = (v_embed + u_embed) / 2\n",
    "word_embed[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c10b5d-82c8-46bc-9061-4773dd5132c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's write a function to get embedding given a word\n",
    "def get_embed_sg_ng(word):\n",
    "    id_tensor = torch.LongTensor([word2index[word]]).to(device)   # ← move to GPU\n",
    "    v_embed = model_sg_neg.embedding_v(id_tensor)\n",
    "    u_embed = model_sg_neg.embedding_u(id_tensor) \n",
    "    word_embed = (v_embed + u_embed) / 2 \n",
    "    x, y = word_embed[0][0].item(), word_embed[0][1].item()\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1cb8fc-c56c-4c24-be7c-fe352c79b2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "for i, word in enumerate(vocab[:100]): #loop each unique vocab\n",
    "    x, y = get_embed_sg_ng(word)\n",
    "    plt.scatter(x, y)\n",
    "    plt.annotate(word, xy=(x, y), xytext=(5, 2), textcoords='offset points')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd5f73c-81d4-4762-8fe3-f1e328939855",
   "metadata": {},
   "source": [
    "### 7. Cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928e1281-47ff-4ba7-b7cf-f4ef8a71ddd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's try similarity between first and second, and second and third\n",
    "tobacco_ng        = get_embed_sg_ng('tobacco')\n",
    "fruit_ng        = get_embed_sg_ng('fruit')\n",
    "breach_ng       = get_embed_sg_ng('breach')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa85c27-2a87-4b50-ab0e-e69882e92e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#numpy version\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "def cos_sim(a, b):\n",
    "    cos_sim = dot(a, b)/(norm(a)*norm(b))\n",
    "    return cos_sim\n",
    "\n",
    "print(f\"tobacco vs. fruit: \",        cos_sim(tobacco_ng, fruit_ng))\n",
    "print(f\"tobacco vs. breach: \",       cos_sim(tobacco_ng, breach_ng))\n",
    "print(f\"tobacco vs. tobacco: \",          cos_sim(tobacco_ng, tobacco_ng))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698b8cf4-26cf-442d-b910-f34ff23234f4",
   "metadata": {},
   "source": [
    "### Glove"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5303f10b-ec8c-442f-9fb5-d2080c8c52d9",
   "metadata": {},
   "source": [
    "### 1. Define some very simple data for understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8802799f-d2a7-4e2e-bdde-4a327c056384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import nltk\n",
    "nltk.download('reuters')\n",
    "from nltk.corpus import reuters\n",
    "from nltk.tokenize import word_tokenize\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Create an empty list to store all Reuters news documents\n",
    "documents = []\n",
    "\n",
    "# Loop through each file ID available in the Reuters corpus\n",
    "for fileid in reuters.fileids():\n",
    "    \n",
    "    # Read the full raw text of the current Reuters news file\n",
    "    text = reuters.raw(fileid)\n",
    "    \n",
    "    # Append (store) the text of the document into the documents list\n",
    "    documents.append(text)\n",
    "    \n",
    "# Tokenize and clean the text documents\n",
    "import string\n",
    "\n",
    "# Create an empty list to store the cleaned corpus\n",
    "corpus = []\n",
    "\n",
    "# Loop through each document in the documents list\n",
    "for doc in documents:\n",
    "    \n",
    "    # Convert text to lowercase and tokenize into individual words\n",
    "    tokens = word_tokenize(doc.lower())\n",
    "    \n",
    "    # Keep only alphabetic tokens (removes numbers, punctuation, symbols)\n",
    "    words = [w for w in tokens if w.isalpha()]\n",
    "    \n",
    "    # Add the cleaned list of words to the corpus\n",
    "    corpus.append(words)\n",
    "# Display the first 2 cleaned documents\n",
    "corpus[:2]# Output the number of documents in the corpus\n",
    "print(f\"Number of documents in the corpus: {len(corpus)}\")# Output the first cleaned document\n",
    "print(f\"First cleaned document: {corpus[0]}\")# Output the number of documents in the corpus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b2a430-9e50-4cfb-95e3-6fd42273a93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize and clean the text documents\n",
    "import string\n",
    "\n",
    "# Create an empty list to store the cleaned corpus\n",
    "corpus = []\n",
    "\n",
    "# Loop through each document in the documents list\n",
    "for doc in documents:\n",
    "    \n",
    "    # Convert text to lowercase and tokenize into individual words\n",
    "    tokens = word_tokenize(doc.lower())\n",
    "    \n",
    "    # Keep only alphabetic tokens (removes numbers, punctuation, symbols)\n",
    "    words = [w for w in tokens if w.isalpha()]\n",
    "    \n",
    "    # Add the cleaned list of words to the corpus\n",
    "    corpus.append(words)\n",
    "# Display the first 2 cleaned documents\n",
    "corpus[:2]# Output the number of documents in the corpus\n",
    "print(f\"Number of documents in the corpus: {len(corpus)}\")# Output the first cleaned document\n",
    "print(f\"First cleaned document: {corpus[0]}\")# Output the number of documents in the corpus\n",
    "corpus = corpus[:100]  # limit corpus size for faster training\n",
    "\n",
    "\n",
    "# Get word sequences and extract unique words (vocabulary)\n",
    "\n",
    "# Define a lambda function to flatten a list of lists into a single list\n",
    "flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "\n",
    "# Flatten the corpus (list of documents) and extract unique words using set\n",
    "vocab = list(set(flatten(corpus)))\n",
    "\n",
    "# Display the first word in the vocabulary list\n",
    "vocab[1]\n",
    "\n",
    "#vocab size\n",
    "voc_size = len(vocab)\n",
    "print(voc_size)\n",
    "\n",
    "# Numericalization: convert words into numerical indices\n",
    "\n",
    "# Create a dictionary that maps each word in the vocabulary to a unique integer index\n",
    "word2index = {w: i for i, w in enumerate(vocab)}\n",
    "word2index['lives'] # Get the index of the first word in the vocabulary\n",
    "\n",
    "# Append a special token for unknown (out-of-vocabulary) words\n",
    "vocab.append('<UNK>')\n",
    "\n",
    "# Create a reverse mapping from index to word\n",
    "# This dictionary allows us to convert numerical indices back into words\n",
    "# It is useful for interpreting model outputs and debugging\n",
    "index2word = {v: k for k, v in word2index.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82c9714-ef58-4deb-af50-7ba1febde8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2. Build Co-occurence Matrix X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6748f61-4a6c-4e4b-8840-e1086864366c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_skipgram(window_size = 2):\n",
    "    # Make skip gram of custom size window\n",
    "    skip_grams = []\n",
    "\n",
    "    for sent in corpus:\n",
    "        for target_index in range(window_size, len(sent) - window_size):\n",
    "            target = sent[target_index]\n",
    "            context = []\n",
    "            count = window_size # count of context words to pick on the left and right\n",
    "            while count > 0:\n",
    "                # for default window, it will get the left most and right most word\n",
    "                # then the second left most and second right most word\n",
    "                context.append(sent[target_index - count])\n",
    "                context.append(sent[target_index + count])\n",
    "                count -= 1\n",
    "\n",
    "            for word in context:\n",
    "                skip_grams.append((target, word))\n",
    "    return skip_grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e74833d-0135-46dc-ba88-f157b4c30fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_grams = get_skipgram(2)\n",
    "skip_grams[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e65b10-9d79-4be5-a347-441eb814acb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ik_skipgram = Counter(skip_grams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16fe76c-3597-48e9-9d48-7a0a33379584",
   "metadata": {},
   "outputs": [],
   "source": [
    "#simply a normalized function...don't worry too much\n",
    "def weighting(w_i, w_j, X_ik):\n",
    "        \n",
    "    #check whether the co-occurrences exist between these two words\n",
    "    try:\n",
    "        x_ij = X_ik[(w_i, w_j)]\n",
    "    except:\n",
    "        x_ij = 1  #if does not exist, set it to 1\n",
    "                \n",
    "    x_max = 100 #100 # fixed in paper  #cannot exceed 100 counts\n",
    "    alpha = 0.75\n",
    "    \n",
    "    #if co-occurrence does not exceed 100, scale it based on some alpha\n",
    "    if x_ij < x_max:\n",
    "        result = (x_ij/x_max)**alpha  #scale it\n",
    "    else:\n",
    "        result = 1  #if is greater than max, set it to 1 maximum\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a0eceb-ca2f-4a48-b9aa-eeda1cc6a01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations_with_replacement\n",
    "\n",
    "X_ik = {}  #for keeping the co-occurences\n",
    "weighting_dic = {} #scaling the percentage of sampling\n",
    "\n",
    "for bigram in combinations_with_replacement(vocab, 2):\n",
    "    if X_ik_skipgram.get(bigram) is not None:  #matches \n",
    "        co_occer = X_ik_skipgram[bigram]  #get the count from what we already counted\n",
    "        X_ik[bigram] = co_occer + 1 # + 1 for stability issue\n",
    "        X_ik[(bigram[1],bigram[0])] = co_occer+1   #count also for the opposite\n",
    "    else:\n",
    "        pass\n",
    "        \n",
    "    weighting_dic[bigram] = weighting(bigram[0], bigram[1], X_ik)\n",
    "    weighting_dic[(bigram[1], bigram[0])] = weighting(bigram[1], bigram[0], X_ik)\n",
    "\n",
    "# print(f\"{X_ik=}\")\n",
    "# print(f\"{weighting_dic=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ff8ea0-cc3b-45f4-a639-5d375344bb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def random_batch(batch_size, word_sequence, skip_grams, X_ik, weighting_dic):\n",
    "    \n",
    "    # convert to id since our skip_grams are words, not yet ids\n",
    "    skip_grams_id = [\n",
    "        (word2index[pair[0]], word2index[pair[1]]) \n",
    "        for pair in skip_grams\n",
    "    ]\n",
    "    \n",
    "    random_inputs = []\n",
    "    random_labels = []\n",
    "    random_coocs  = []\n",
    "    random_weightings = []\n",
    "    \n",
    "    random_index = np.random.choice(\n",
    "        range(len(skip_grams_id)),\n",
    "        batch_size,\n",
    "        replace=False\n",
    "    )\n",
    "        \n",
    "    for i in random_index:\n",
    "        random_inputs.append([skip_grams_id[i][0]])  # target \n",
    "        random_labels.append([skip_grams_id[i][1]])  # context j\n",
    "\n",
    "        # get co-occurrence X_ij\n",
    "        pair = skip_grams[i]\n",
    "        try:\n",
    "            cooc = X_ik[pair]\n",
    "        except:\n",
    "            cooc = 1\n",
    "        random_coocs.append([math.log(cooc)])\n",
    "        \n",
    "        # get weighting f(X_ij)\n",
    "        weighting = weighting_dic[pair]\n",
    "        random_weightings.append([weighting])\n",
    "                    \n",
    "    return (\n",
    "        np.array(random_inputs),\n",
    "        np.array(random_labels),\n",
    "        np.array(random_coocs),\n",
    "        np.array(random_weightings)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c9fed5-be6d-45d3-a0a2-d86910a3ac7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Testing the method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a1175e-d522-4633-9a61-b6b8fccc5dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing the method\n",
    "batch_size = 2 # mini-batch size\n",
    "input_batch, target_batch, cooc_batch, weighting_batch = random_batch(batch_size, corpus, skip_grams, X_ik, weighting_dic)\n",
    "\n",
    "print(\"Input: \", input_batch)\n",
    "print(\"Target: \", target_batch)\n",
    "print(\"Cooc: \", cooc_batch)\n",
    "print(\"Weighting: \", weighting_batch)\n",
    "\n",
    "#we will convert them to tensor during training, so don't worry..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1795389-1ac2-4288-b3b0-5c1914d4c4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GloVe(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size,embed_size):\n",
    "        super(GloVe,self).__init__()\n",
    "        self.embedding_center = nn.Embedding(vocab_size, embed_size) # center embedding\n",
    "        self.embedding_outside = nn.Embedding(vocab_size, embed_size) # out embedding\n",
    "        \n",
    "        self.v_bias = nn.Embedding(vocab_size, 1)\n",
    "        self.u_bias = nn.Embedding(vocab_size, 1)\n",
    "        \n",
    "    def forward(self, center_words, target_words, coocs, weighting):\n",
    "        center_embeds = self.embedding_center(center_words) # [batch_size, 1, emb_size]\n",
    "        target_embeds = self.embedding_outside(target_words) # [batch_size, 1, emb_size]\n",
    "        \n",
    "        center_bias = self.v_bias(center_words).squeeze(1)\n",
    "        target_bias = self.u_bias(target_words).squeeze(1)\n",
    "        \n",
    "        inner_product = target_embeds.bmm(center_embeds.transpose(1, 2)).squeeze(2)\n",
    "        #[batch_size, 1, emb_size] @ [batch_size, emb_size, 1] = [batch_size, 1, 1] = [batch_size, 1]\n",
    "        \n",
    "        #note that coocs already got log\n",
    "        loss = weighting*torch.pow(inner_product +center_bias + target_bias - coocs, 2)\n",
    "        \n",
    "        return torch.sum(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e614e9-19b0-4748-a0cb-a4a7ccbeacb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size     = 32 # mini-batch size\n",
    "embedding_size = 2 #so we can later plot\n",
    "model_glove    = GloVe(voc_size, embedding_size)\n",
    "model_glove    = model_glove.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model_glove.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889abe64-0322-4095-87be-c602c1850b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2bc598b-3a83-4900-aa8d-13c31e62976a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5000\n",
    "import time\n",
    "\n",
    "# >>> ADD: record total training start time\n",
    "total_start_time = time.time()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    input_batch, target_batch, cooc_batch, weighting_batch = random_batch(\n",
    "        batch_size, corpus, skip_grams, X_ik, weighting_dic\n",
    "    )\n",
    "    \n",
    "    input_batch  = torch.LongTensor(input_batch)          # [batch_size, 1]\n",
    "    target_batch = torch.LongTensor(target_batch)         # [batch_size, 1]\n",
    "    cooc_batch   = torch.FloatTensor(cooc_batch)          # [batch_size, 1]\n",
    "    weighting_batch = torch.FloatTensor(weighting_batch)  # [batch_size, 1]\n",
    "\n",
    "    # to cuda\n",
    "    input_batch = input_batch.to(device)\n",
    "    target_batch = target_batch.to(device)\n",
    "    cooc_batch = cooc_batch.to(device)\n",
    "    weighting_batch = weighting_batch.to(device)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss = model_glove(input_batch, target_batch, cooc_batch, weighting_batch)\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    end = time.time()\n",
    "    \n",
    "    epoch_mins, epoch_secs = epoch_time(start, end)\n",
    "\n",
    "    if (epoch + 1) % 1000 == 0:\n",
    "        print(f\"Epoch: {epoch + 1} | cost: {loss:.6f} | time: {epoch_mins}m {epoch_secs}s\")\n",
    "\n",
    "# >>> ADD: record total training end time\n",
    "total_end_time = time.time()\n",
    "\n",
    "# >>> ADD: compute total training time\n",
    "total_training_time = total_end_time - total_start_time\n",
    "\n",
    "# >>> ADD: final reporting (for Task-2 table)\n",
    "print(f\"\\nTotal training time (GloVe): {total_training_time:.2f} seconds\")\n",
    "print(f\"Final training loss (GloVe): {loss.item():.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb071d6a-3211-4a8b-9ac0-89fa530240be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "torch.save(model_glove.state_dict(), 'model/glove_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27afad30-ffc5-4b3b-9ec1-2f79c18c6a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model using pickle\n",
    "import pickle\n",
    "pickle.dump(model_glove, open('model/glove.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042173ef-65ff-4101-9bfe-d9b444e3d5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embed_glove(word):\n",
    "    id_tensor = torch.LongTensor([word2index[word]])\n",
    "    id_tensor = id_tensor.to(device)\n",
    "    v_embed = model_glove.embedding_center(id_tensor)\n",
    "    u_embed = model_glove.embedding_outside(id_tensor) \n",
    "    word_embed = (v_embed + u_embed) / 2 \n",
    "    x, y = word_embed[0][0].item(), word_embed[0][1].item()\n",
    "\n",
    "    return x, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76861e1-aa35-4aa0-bcdc-98301ef1c737",
   "metadata": {},
   "outputs": [],
   "source": [
    "tobacco_glove      = get_embed_glove('tobacco')\n",
    "fruit_glove        = get_embed_glove('fruit')\n",
    "breach_glove       = get_embed_glove('breach')\n",
    "print('embedding for tobacco:', tobacco_glove)\n",
    "print('embedding for fruit:', fruit_glove)\n",
    "print('embedding for breach:', breach_glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba9f6ca-927d-4dd8-b6b1-768ebbb30a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "def cos_sim(a, b):\n",
    "    cos_sim = dot(a, b)/(norm(a)*norm(b))\n",
    "    return cos_sim\n",
    "print(f\"tobacco vs fruit: {cos_sim(tobacco_glove, fruit_glove):.4f}\")\n",
    "print(f\"tobacco vs breach: {cos_sim(tobacco_glove, breach_glove):.4f}\")\n",
    "print(f\"fruit vs breach: {cos_sim(fruit_glove, breach_glove):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c5c8a8-8c16-4fcc-ba6a-23d929525545",
   "metadata": {},
   "source": [
    "### Glove (Genism)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b369695b-f6c2-4d4c-831b-8eebea7e879d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "from gensim.test.utils import datapath\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "\n",
    "glove_file = r\"C:\\Users\\User\\Downloads\\glove.6B.100d.txt\"\n",
    "\n",
    "model_gensim = KeyedVectors.load_word2vec_format(\n",
    "    glove_file,\n",
    "    binary=False,\n",
    "    no_header=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef2f60f-0f7b-4473-9bf1-d9d0461368ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Word similarity\n",
    "similarity = model_gensim.similarity('king', 'queen')\n",
    "print(f\"Similarity between 'king' and 'queen': {similarity:.4f}\")\n",
    "\n",
    "# Example: Word analogy\n",
    "result = model_gensim.most_similar(positive=['king', 'woman'], negative=['man'])\n",
    "print(\"King - Man + Woman = \", result[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17030a6e-e42e-4276-97b8-db1a66b06f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gensim['coffee'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227f97ea-d86a-4c6b-a712-d88aef08a7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gensim.most_similar('coffee')[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b26e5e9-61fe-4170-b62f-21d5d277cc0f",
   "metadata": {},
   "source": [
    "## TASK -2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7602e3de-ef51-4cc7-a14a-0f1df6df2b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_word(word1, word2, word3, embeddings, word_to_index, index_to_word):\n",
    "    \"\"\"\n",
    "    Predicts a word analogy using vector arithmetic.\n",
    "    Example: word1 - word2 + word3 ≈ ?\n",
    "    (e.g., king - man + woman ≈ queen)\n",
    "    \n",
    "    Parameters:\n",
    "    word1, word2, word3 : str\n",
    "        Input words forming the analogy\n",
    "    embeddings : function or dict-like\n",
    "        Function that returns the embedding vector for a given word\n",
    "    word_to_index : dict\n",
    "        Mapping from word to its index in the vocabulary\n",
    "    index_to_word : dict\n",
    "        Mapping from index to word (not directly used here, but kept for completeness)\n",
    "    \"\"\"\n",
    "\n",
    "    # Retrieve embedding vectors for the three input words\n",
    "    vec1 = np.array(embeddings(word1))  # Vector representation of word1\n",
    "    vec2 = np.array(embeddings(word2))  # Vector representation of word2\n",
    "    vec3 = np.array(embeddings(word3))  # Vector representation of word3\n",
    "\n",
    "    # Perform vector arithmetic to compute the target analogy vector\n",
    "    # predicted_vec ≈ vec(word1) - vec(word2) + vec(word3)\n",
    "    predicted_vec = vec1 - vec2 + vec3\n",
    "\n",
    "    # Initialize variables to track the most similar word\n",
    "    max_similarity = -1        # Lowest possible cosine similarity\n",
    "    best_word = None           # Placeholder for the predicted word\n",
    "\n",
    "    # Iterate over all words in the vocabulary\n",
    "    for word, index in word_to_index.items():\n",
    "\n",
    "        # Skip the input words to avoid trivial predictions\n",
    "        if word in [word1, word2, word3]:\n",
    "            continue\n",
    "\n",
    "        # Compute cosine similarity between predicted vector and current word vector\n",
    "        similarity = cos_sim(predicted_vec, embeddings(word))\n",
    "\n",
    "        # Update the best match if a higher similarity is found\n",
    "        if similarity > max_similarity:\n",
    "            max_similarity = similarity\n",
    "            best_word = word\n",
    "\n",
    "    # Return the word whose embedding is closest to the predicted vector\n",
    "    return best_word\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca4e3a9-d5de-409f-8cde-ba58ec07d1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate accuracy of word analogy predictions\n",
    "def evaluate_analogies(analogy_dataset, embeddings, word_to_index):\n",
    "    \"\"\"\n",
    "    Evaluates the accuracy of word analogy predictions.\n",
    "    Each analogy is of the form:\n",
    "    (word1, word2, word3, word4) meaning word1 - word2 + word3 ≈ word4\n",
    "\n",
    "    Parameters:\n",
    "    analogy_dataset : list of tuples\n",
    "        List of analogy questions (word1, word2, word3, word4)\n",
    "    embeddings : function or dict-like\n",
    "        Function that returns the embedding vector for a given word\n",
    "    word_to_index : dict\n",
    "        Mapping from word to index for vocabulary lookup\n",
    "\n",
    "    Returns:\n",
    "    float\n",
    "        Accuracy of analogy prediction (correct / total)\n",
    "    \"\"\"\n",
    "\n",
    "    correct = 0  # Counter for correctly predicted analogies\n",
    "    total = 0    # Counter for total evaluated analogies\n",
    "\n",
    "    # Iterate through each analogy question in the dataset\n",
    "    for analogy in analogy_dataset:\n",
    "        word1, word2, word3, word4 = analogy\n",
    "\n",
    "        # Skip the analogy if any word is not present in the vocabulary\n",
    "        if (word1 not in word_to_index or\n",
    "            word2 not in word_to_index or\n",
    "            word3 not in word_to_index or\n",
    "            word4 not in word_to_index):\n",
    "            continue\n",
    "\n",
    "        # Predict the fourth word using vector arithmetic\n",
    "        predicted_word = predict_word(\n",
    "            word1,\n",
    "            word2,\n",
    "            word3,\n",
    "            embeddings,\n",
    "            word_to_index,\n",
    "            {v: k for k, v in word_to_index.items()}  # Create index-to-word mapping\n",
    "        )\n",
    "\n",
    "        # Check if the predicted word matches the expected answer\n",
    "        if predicted_word == word4:\n",
    "            correct += 1\n",
    "\n",
    "        # Increment the total number of evaluated analogies\n",
    "        total += 1\n",
    "\n",
    "    # Return accuracy; avoid division by zero if no analogies were evaluated\n",
    "    return correct / total if total > 0 else 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc54d01-c1fc-42f7-9c14-e1c76b56cb78",
   "metadata": {},
   "source": [
    "Dataset\n",
    "\n",
    "Source credit: https://www.fit.vut.cz/person/imikolov/public/rnnlm/word-test.v1.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a05b0fd-ea9a-476a-ab36-ceb5526afb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"capital-common-countries.txt\", \"r\") as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "semantic_dataset = []\n",
    "for line in lines:\n",
    "    # Split the line into words\n",
    "    words = line.strip().split()\n",
    "    if len(words) == 4:\n",
    "        semantic_dataset.append([words[0], words[1], words[2], words[3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abdfe11-c06e-416c-bfe1-1243561e04ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"past_tense.txt\", \"r\") as file:\n",
    "    lines = file.readlines()\n",
    "past_tense_dataset = []\n",
    "for line in lines:\n",
    "    # Split the line into words\n",
    "    words = line.strip().split()\n",
    "    if len(words) == 4:\n",
    "        past_tense_dataset.append([words[0], words[1], words[2], words[3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e911a3c-f91c-4093-bbc5-1d9978e7aded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick check\n",
    "semantic_dataset[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6482d251-f433-4f29-bd94-34bb506d2860",
   "metadata": {},
   "outputs": [],
   "source": [
    "past_tense_dataset[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934a5912-8b9b-4a88-93a3-364ba215de7a",
   "metadata": {},
   "source": [
    "#### Syntactic Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9a470f-e732-4b54-a9ed-d1d870e2a564",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = evaluate_analogies(past_tense_dataset, get_embed_sg, word2index)\n",
    "print(f\"Syntactic Accuracy - skipgram: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b37559-7a64-4ad4-a5ff-3343b5c3e163",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = evaluate_analogies(past_tense_dataset, get_embed_sg_ng, word2index)\n",
    "print(f\"Syntactic Accuracy - negative sample: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b511e24-42f5-4386-9727-83b8ca57a9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = evaluate_analogies(past_tense_dataset, get_embed_glove, word2index)\n",
    "print(f\"Syntactic Accuracy - glove: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b14567-116f-43cc-9133-1807f1cb3e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = model_gensim.evaluate_word_analogies(\"past_tense.txt\")[0]\n",
    "print(f\"Syntactic Accuracy - gensim: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10516873-88a3-478f-b2ca-2c9a42e87a1e",
   "metadata": {},
   "source": [
    "#### Semantic Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70be0ef5-b413-4618-964e-ad85d5e560d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = evaluate_analogies(semantic_dataset, get_embed_sg, word2index)\n",
    "print(f\"Semantic Accuracy - skipgram: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff521330-fd45-4023-9dad-48dc2ec0389d",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = evaluate_analogies(semantic_dataset, get_embed_sg_ng, word2index)\n",
    "print(f\"Semantic Accuracy - negative sample: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7365a2a1-02d2-420f-8023-afdcdb984aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = evaluate_analogies(semantic_dataset, get_embed_glove, word2index)\n",
    "print(f\"Semantic Accuracy - glove: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8f06ad-56a1-423b-b44e-39cc78444389",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = model_gensim.evaluate_word_analogies(\"capital-common-countries.txt\")[0]\n",
    "print(f\"Semantic Accuracy - gensim: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6653f18a-957d-4cd3-b1fc-5f90bb90dae2",
   "metadata": {},
   "source": [
    "| Model              | Window Size | Training Loss | Training Time (sec) | Syntactic Accuracy | Semantic Accuracy |\n",
    "|--------------------|-------------|---------------|---------------------|--------------------|-------------------|\n",
    "| Skip-gram          | 2           | 8.0564        | 433.89              | 3.33%              | 0.00%             |\n",
    "| Skip-gram (NEG)    | 2           | 14.3561       | 474.58              | 0.00%              | 0.00%             |\n",
    "| GloVe (scratch)    | 2           | 9.5779        | 98.30               | 0.00%              | 0.00%             |\n",
    "| GloVe (Gensim)     | –           | –             | –                   | 55.45%             | 93.87%            |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3662ac-aac1-4686-920b-74f5d36f8883",
   "metadata": {},
   "source": [
    "Similarity Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff12dcc-3a7c-41fa-b961-157210e9a800",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "columns = ['Word 1', 'Word 2', 'Similarity Index']\n",
    "\n",
    "df = pd.read_csv('wordsim/combined.csv', sep=',', header=None, names=columns)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37aa318-c0e6-478f-83e9-a75a3d36f38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include = 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d862dce-df90-4ac8-8634-9f1ecfc8bf82",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df.iterrows():\n",
    "    word_1 = row['Word 1']\n",
    "    word_2 = row['Word 2']\n",
    "\n",
    "    try:\n",
    "        embed_1_neg_samp    = get_embed_sg_ng(word_1)\n",
    "        embed_2_neg_samp    = get_embed_sg_ng(word_2)\n",
    "        embed_1_skip_gram   = get_embed_sg(word_1)\n",
    "        embed_2_skip_gram   = get_embed_sg(word_2)\n",
    "        embed_1_glove       = get_embed_glove(word_1)\n",
    "        embed_2_glove       = get_embed_glove(word_2)\n",
    "\n",
    "    except KeyError:\n",
    "        # Replacing missing embeddings with the embedding of '<UNK>'\n",
    "        embed_1_neg_samp    = get_embed_sg_ng('<UNK>')\n",
    "        embed_2_neg_samp    = get_embed_sg_ng('<UNK>')\n",
    "        embed_1_skip_gram   = get_embed_sg('<UNK>')\n",
    "        embed_2_skip_gram   = get_embed_sg('<UNK>')\n",
    "        embed_1_glove       = get_embed_glove('<UNK>')\n",
    "        embed_2_glove       = get_embed_glove('<UNK>')\n",
    "\n",
    "    # Computing dot product\n",
    "    df.at[index, 'dot_product_neg_samp'] = np.dot(embed_1_neg_samp, embed_2_neg_samp)\n",
    "    df.at[index, 'dot_product_skip_gram'] = np.dot(embed_1_skip_gram, embed_2_skip_gram)\n",
    "    df.at[index, 'dot_product_glove'] = np.dot(embed_1_glove, embed_2_glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d149af2-7b8c-4208-818e-43cd4085c0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr\n",
    "\n",
    "# Computing the Spearman correlation\n",
    "correlation_pos, _ = spearmanr(df['Similarity Index'], df['dot_product_skip_gram'])\n",
    "correlation_neg, _ = spearmanr(df['Similarity Index'], df['dot_product_neg_samp'])\n",
    "correlation_glove, _ = spearmanr(df['Similarity Index'], df['dot_product_glove'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92bdcf16-9928-49d8-83c0-174e06c637eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Spearman Correlation Coefficient of Skipgram: {correlation_pos:.4f}\")\n",
    "print(f\"Spearman Correlation Coefficient of Skipgram with Negative Sampling: {correlation_neg:.4f}\")\n",
    "print(f\"Spearman Correlation Coefficient of Glove: {correlation_glove:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29311acc-edf4-4f6f-b905-b9f6b9a1e346",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding y_true based on the mean of similarity index in the df\n",
    "y_true = df['Similarity Index'].mean()\n",
    "\n",
    "print(f\"y_true: {y_true:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7665156-318b-4de6-b301-aa4062f0a509",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_coefficient = model_gensim.evaluate_word_pairs(\n",
    "    'wordsim/combined.csv',\n",
    "    delimiter=','\n",
    ")\n",
    "print(f\"Spearman Correlation Correlation coefficient of Glove (genism): {correlation_coefficient[1][0]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3202f64-37aa-45a0-96d9-dc0708b11783",
   "metadata": {},
   "outputs": [],
   "source": [
    "| Model | Skipgram | NEG   | GloVe | GloVe (gensim) | Y_true |\n",
    "|-------|----------|-------|-------|----------------|--------|\n",
    "| MSE   | 0.01058   | 0.0241| 0.0510 | 0.53           | 5.86   |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5733025-d042-44c7-979a-be7eb0aab6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embed_for_corpus(model, words):\n",
    "    embeddings = {}\n",
    "\n",
    "    for word in words:\n",
    "        if word not in word2index:\n",
    "            continue  # skip OOV safely\n",
    "\n",
    "        index = word2index[word]\n",
    "        word_tensor = torch.LongTensor([index]).to(device)\n",
    "\n",
    "        # Handle Skip-gram / Skip-gram + NEG\n",
    "        if hasattr(model, 'embedding_v') and hasattr(model, 'embedding_u'):\n",
    "            embed_c = model.embedding_v(word_tensor)\n",
    "            embed_o = model.embedding_u(word_tensor)\n",
    "\n",
    "        # Handle GloVe-style models\n",
    "        elif hasattr(model, 'embedding_center') and hasattr(model, 'embedding_outside'):\n",
    "            embed_c = model.embedding_center(word_tensor)\n",
    "            embed_o = model.embedding_outside(word_tensor)\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"Unknown embedding structure in model\")\n",
    "\n",
    "        embed = (embed_c + embed_o) / 2\n",
    "        embeddings[word] = embed.squeeze().detach().cpu().numpy()\n",
    "\n",
    "    return embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a603461-b93f-4d72-9fcc-26a2f08fa00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_whole_glove = get_embed_for_corpus(model_glove, vocab)\n",
    "embed_whole_neg_skg = get_embed_for_corpus(model_sg_neg, vocab)\n",
    "embed_whole_skg = get_embed_for_corpus(model_glove, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5272df-5456-4b55-8596-ad99760cffa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model/model_gensim.pkl', 'wb') as model_file:\n",
    "    pickle.dump(model_gensim, model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2354870e-0ce1-49cb-8508-2c6d352f5b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model/embed_skipgram_negative.pkl', 'wb') as pickle_file:\n",
    "    pickle.dump(embed_whole_neg_skg, pickle_file)\n",
    "\n",
    "print(f\"File saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850dd727-14ca-49e1-8bd6-ae37e5129597",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model/embed_skipgram.pkl', 'wb') as pickle_file:\n",
    "    pickle.dump(embed_whole_skg, pickle_file)\n",
    "\n",
    "print(f\"File saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3aafbe9-522c-4796-987d-a7a7653ecc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model/embed_glove.pkl', 'wb') as pickle_file:\n",
    "    pickle.dump(embed_whole_glove, pickle_file)\n",
    "\n",
    "print(f\"File saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729f0392-7b19-4dfc-8fd8-25cd51943178",
   "metadata": {},
   "source": [
    "Observation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1511b1-a6c6-4273-8248-cbfb3561a2bc",
   "metadata": {},
   "source": [
    "With a window size of 2, the Skip-gram model achieved a training loss of 8.06, while Skip-gram with negative sampling recorded a higher loss of 14.36. The GloVe model trained from scratch showed a loss of 9.58, placing it between the two Skip-gram variants.\n",
    "\n",
    "All models were trained for 5000 epochs. Skip-gram took 433.89 seconds, Skip-gram with negative sampling required 474.58 seconds, and GloVe was the fastest, completing training in 98.30 seconds.\n",
    "\n",
    "In analogy evaluation, the models trained from scratch performed poorly. Skip-gram achieved a syntactic accuracy of 3.33%, while Skip-gram with negative sampling and GloVe both achieved 0%. All three scratch models also recorded 0% semantic accuracy, which was expected given the small corpus size and limited training setup.\n",
    "\n",
    "In contrast, the pretrained GloVe (Gensim) model performed significantly better, achieving 55.45% syntactic accuracy and 93.87% semantic accuracy.\n",
    "\n",
    "The word similarity evaluation further supports this result. The pretrained GloVe model achieved a Spearman correlation of 0.53, showing good agreement with human judgments, whereas the scratch-trained models showed very weak correlation.\n",
    "\n",
    "Overall, the poor performance of the scratch models is mainly due to the limited corpus size and simple hyperparameter settings. With larger data and better tuning, their performance could be improved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb2d58b-b491-469a-9218-0f3f826222a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myConda)",
   "language": "python",
   "name": "myconda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
